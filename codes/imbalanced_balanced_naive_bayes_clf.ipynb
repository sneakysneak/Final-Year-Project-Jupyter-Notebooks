{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description\n",
    "Imbalanced and balanced data sampling and naive bayes classifier implementation.\n",
    "\n",
    "All read file variables (like train.csv, embeddings files etc) are set to relative path, which means just drag the competition files in to the program's folder and it reads in them automatically. \n",
    "Furthermore, I turned off the support for AMD Radeon GPUs, turn it on if necessary (for quicker computing on Radeon machines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sneakysneak/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/sneakysneak/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/sneakysneak/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/sneakysneak/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/sneakysneak/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/sneakysneak/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# support for AMD Radeon GPU - if you run this on AMD Radeon GPU computer, then use it\n",
    "\n",
    "# import plaidml.keras\n",
    "# plaidml.keras.install_backend()\n",
    "# import os\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "\n",
    "# keras layers, tokenizer, model, sequential etc.\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, SimpleRNN, RNN, LSTM, GRU, Embedding, Dropout, Activation, Flatten, Conv1D, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "import tensorflow as tf\n",
    "# time for idle the system after deleting models and embedding to test in one notebook\n",
    "import time\n",
    "# linear algebra\n",
    "import numpy as np \n",
    "# data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pandas as pd \n",
    "# monitor loading time where it is supported\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import gc\n",
    "\n",
    "random_seed = 63445\n",
    "lsize = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1306122, 3)\n",
      "Test shape :  (375806, 2)\n"
     ]
    }
   ],
   "source": [
    "# train_df = pd.read_csv(\"/Users/sneakysneak/Downloads/quora_dataset/train.csv\")\n",
    "# test_df = pd.read_csv(\"/Users/sneakysneak/Downloads/quora_dataset/test.csv\")]\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "print(\"Train shape : \",train_df.shape)\n",
    "print(\"Test shape : \",test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1306122 entries, 0 to 1306121\n",
      "Data columns (total 3 columns):\n",
      "qid              1306122 non-null object\n",
      "question_text    1306122 non-null object\n",
      "target           1306122 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 29.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training dataset into train and val sample. \n",
    "# Cross validation is a time consuming process and so \n",
    "# let us do simple train val split.\n",
    "\n",
    "## split to train and val\n",
    "# train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=2018)\n",
    "# no random state\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1)\n",
    "\n",
    "## configuration values \n",
    "embed_size = 300 # the size of each word vector\n",
    "max_features = 50000 # the size of unique words in use - the number of rows in the embedding vector\n",
    "maxlen = 100 # the size of the number of words in each question\n",
    "\n",
    "## first fill all missing values up\n",
    "train_X = train_df[\"question_text\"].fillna(\"_na_\").values\n",
    "val_X = val_df[\"question_text\"].fillna(\"_na_\").values\n",
    "test_X = test_df[\"question_text\"].fillna(\"_na_\").values\n",
    "\n",
    "## tokenize with Keras\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_X))\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "val_X = tokenizer.texts_to_sequences(val_X)\n",
    "\n",
    "test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "## sentence padding\n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "val_X = pad_sequences(val_X, maxlen=maxlen)\n",
    "test_X = pad_sequences(test_X, maxlen=maxlen)\n",
    "\n",
    "## save the target values as train_y and val_y\n",
    "train_y = train_df['target'].values\n",
    "val_y = val_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[[    0     0     0 ...   181 22659 11952]\n",
      " [    0     0     0 ...   429     1   281]\n",
      " [    0     0     0 ...     1   597    94]\n",
      " ...\n",
      " [    0     0     0 ...     6    63   643]\n",
      " [    0     0     0 ...  3864   387    17]\n",
      " [    0     0     0 ... 21471   296  1032]]\n",
      "[[    0     0     0 ...  2477     6   656]\n",
      " [    0     0     0 ...    29   486   167]\n",
      " [    0     0     0 ...   626     7 28257]\n",
      " ...\n",
      " [    0     0     0 ...    44   554   341]\n",
      " [    0     0     0 ...     6   312   829]\n",
      " [    0     0     0 ...     6 11215  1311]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_y), print(val_y), print(train_X), print(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('int64'), dtype('int64'), dtype('int32'), dtype('int32'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.dtype, val_y.dtype, train_X.dtype, val_X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1175509,), (1175509, 100), (130613,), (130613, 100))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape, train_X.shape, val_y.shape, val_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_metrics(true, preds):\n",
    "    \"\"\"\n",
    "    Function to calculate evaluation metrics \n",
    "    parameters: true values, predictions\n",
    "    prints accuracy, recall, precision and f1 scores\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(true, preds)\n",
    "    precision = precision_score(true, preds)\n",
    "    recall = recall_score(true, preds)\n",
    "    f1score = f1_score(true, preds)\n",
    "    print ('accuracy: {}, precision: {}, recall: {}, f1-score: {}'.format(accuracy, recall, precision, f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB().fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix?? and after metrics\n",
    "preds = cross_val_predict(gnb, train_X, train_y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1087811,   15012],\n",
       "       [  68637,    4049]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(train_y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92938135, 0.92612981, 0.93007789])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(gnb, train_X, train_y, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9288401875272754, precision: 0.05570536279338525, recall: 0.2124232726509627, f1-score: 0.08826446641307072\n"
     ]
    }
   ],
   "source": [
    "my_metrics(train_y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.94      0.99      0.96   1102823\n",
      "     class 1       0.21      0.06      0.09     72686\n",
      "\n",
      "    accuracy                           0.93   1175509\n",
      "   macro avg       0.58      0.52      0.53   1175509\n",
      "weighted avg       0.90      0.93      0.91   1175509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mer ugye a sima metricsnel is defineolni kellett h 0 v 1 alapjan nyomja, volt hh naon jo ertek, \n",
    "# volt h naon dzar, hat ezert ilyen, 2 class kell\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(train_y, preds, labels=[0,1], target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of oversampled data: (2205646, 100)\n",
      "Shape of Y: (2205646,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=random_seed)\n",
    "X_, Y_ = sm.fit_sample(train_X, train_y, )\n",
    "print ('Shape of oversampled data: {}'.format(X_.shape))\n",
    "print ('Shape of Y: {}'.format(Y_.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_converted = np.floor(X_).astype(int)\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_train_pred_balanced = cross_val_predict(gnb, X_converted, Y_, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1088235,   14588],\n",
       "       [1056210,   46613]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_, y_train_pred_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5145195557219971, precision: 0.04226698209957536, recall: 0.7616378817339586, f1-score: 0.08008941396397325\n"
     ]
    }
   ],
   "source": [
    "my_metrics(Y_,y_train_pred_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.51      0.99      0.67   1102823\n",
      "     class 1       0.76      0.04      0.08   1102823\n",
      "\n",
      "    accuracy                           0.51   2205646\n",
      "   macro avg       0.63      0.51      0.38   2205646\n",
      "weighted avg       0.63      0.51      0.38   2205646\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mer ugye a sima metricsnel is defineolni kellett h 0 v 1 alapjan nyomja, volt hh naon jo ertek, \n",
    "# volt h naon dzar, hat ezert ilyen, 2 class kell\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(Y_, y_train_pred_balanced, labels=[0,1], target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5765358532379582, 0.5210465121383439, 0.525619845803696, None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(train_y, preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9288401875272754, 0.9288401875272754, 0.9288401875272754, None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(train_y, preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8956196215699282, 0.9288401875272754, 0.9088886752718844, None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(train_y, preds, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6345524243557141, 0.5145195557219971, 0.3751679552017209, None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(Y_, y_train_pred_balanced, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5145195557219971, 0.5145195557219971, 0.5145195557219971, None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(Y_, y_train_pred_balanced, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6345524243557141, 0.5145195557219971, 0.37516795520172086, None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(Y_, y_train_pred_balanced, average='weighted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
