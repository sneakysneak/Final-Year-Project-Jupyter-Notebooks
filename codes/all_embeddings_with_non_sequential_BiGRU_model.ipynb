{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description\n",
    "In this evaluation a non-Sequentail Bidirectional GRU model is being evaluated firstly with no embeddings, each of the embeddings (glove, paragram and fasttext) and lastly the blend of these embeddings.\n",
    "\n",
    "All read file variables (like train.csv, embeddings files etc) are set to relative path, which means just drag the competition files in to the program's folder and it reads in them automatically. \n",
    "Furthermore, I turned off the support for AMD Radeon GPUs, turn it on if necessary (for quicker computing on Radeon machines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support for AMD Radeon GPU - if you run this on AMD Radeon GPU computer, then use it\n",
    "\n",
    "# import plaidml.keras\n",
    "# plaidml.keras.install_backend()\n",
    "# import os\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "\n",
    "# keras layers, tokenizer, model, sequential etc.\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "import os\n",
    "# time for idle the system after deleting models and embedding to test in one notebook\n",
    "import time\n",
    "# linear algebra\n",
    "import numpy as np \n",
    "# data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pandas as pd \n",
    "# monitor loading time where it is supported\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1306122, 3)\n",
      "Test shape :  (375806, 2)\n"
     ]
    }
   ],
   "source": [
    "# train_df = pd.read_csv(\"/Users/sneakysneak/Downloads/quora_dataset/train.csv\")\n",
    "# test_df = pd.read_csv(\"/Users/sneakysneak/Downloads/quora_dataset/test.csv\")]\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "print(\"Train shape : \",train_df.shape)\n",
    "print(\"Test shape : \",test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split the data frame to train and val\n",
    "train_data_frame, value_data_frame = train_test_split(train_data_frame, test_size=0.1, random_state=2018)\n",
    "\n",
    "## configuration values \n",
    "# 300 \n",
    "embedding_size = 30 # the size of each word vector\n",
    "# 50000\n",
    "max_features = 500 # the size of unique words in use - the number of rows in the embedding vector\n",
    "# 100 \n",
    "max_length_question = 10 # the size of the number of words in each question\n",
    "\n",
    "## first fill all missing values up\n",
    "train_X = train_data_frame[\"question_text\"].fillna(\"_na_\").values\n",
    "val_X = value_data_frame[\"question_text\"].fillna(\"_na_\").values\n",
    "test_X = test_data_frame[\"question_text\"].fillna(\"_na_\").values\n",
    "\n",
    "## tokenize with Keras\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_X))\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "val_X = tokenizer.texts_to_sequences(val_X)\n",
    "test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "## sentence padding\n",
    "train_X = pad_sequences(train_X, maxlen=max_length_question)\n",
    "val_X = pad_sequences(val_X, maxlen=max_length_question)\n",
    "test_X = pad_sequences(test_X, maxlen=max_length_question)\n",
    "\n",
    "## save the target values as train_y and val_y\n",
    "train_y = train_data_frame['target'].values\n",
    "val_y = value_data_frame['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"metal_amd_radeon_pro_560.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 10, 30)            15000     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 10, 128)           36480     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 53,561\n",
      "Trainable params: 53,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_input = Input(shape=(max_length_question,))\n",
    "layer = Embedding(max_features, embedding_size)(model_input)\n",
    "layer = Bidirectional(GRU(64, return_sequences=True))(layer)\n",
    "layer = GlobalMaxPool1D()(layer)\n",
    "layer = Dense(16, activation=\"relu\")(layer)\n",
    "layer = Dropout(0.1)(layer)\n",
    "layer = Dense(1, activation=\"sigmoid\")(layer)\n",
    "model = Model(inputs=model_input, outputs=layer)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/1\n",
      "1175509/1175509 [==============================] - 152s 129us/step - loss: 0.1702 - acc: 0.9419 - val_loss: 0.1603 - val_acc: 0.9426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a50242438>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the model \n",
    "# Set to 1 epoch because of time consuming training time\n",
    "model.fit(train_X, train_y, batch_size=512, epochs=1, validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130613/130613 [==============================] - 8s 64us/step\n",
      "F1 score at threshold 0.1 is 0.16909653191959353\n",
      "F1 score at threshold 0.11 is 0.18121509643335304\n",
      "F1 score at threshold 0.12 is 0.19520216419790742\n",
      "F1 score at threshold 0.13 is 0.21089543260413457\n",
      "F1 score at threshold 0.14 is 0.22616293180163416\n",
      "F1 score at threshold 0.15 is 0.24234003135242985\n",
      "F1 score at threshold 0.16 is 0.26012457998467314\n",
      "F1 score at threshold 0.17 is 0.2752037752037752\n",
      "F1 score at threshold 0.18 is 0.28917236071919966\n",
      "F1 score at threshold 0.19 is 0.3026044028008665\n",
      "F1 score at threshold 0.2 is 0.3164851833793813\n",
      "F1 score at threshold 0.21 is 0.3278069742458117\n",
      "F1 score at threshold 0.22 is 0.33926956304774974\n",
      "F1 score at threshold 0.23 is 0.3493951747644189\n",
      "F1 score at threshold 0.24 is 0.3571047103642254\n",
      "F1 score at threshold 0.25 is 0.3676195565054769\n",
      "F1 score at threshold 0.26 is 0.3747925689075971\n",
      "F1 score at threshold 0.27 is 0.37911970171002446\n",
      "F1 score at threshold 0.28 is 0.38636363636363635\n",
      "F1 score at threshold 0.29 is 0.38949525761403175\n",
      "F1 score at threshold 0.3 is 0.39061014064768\n",
      "F1 score at threshold 0.31 is 0.3897070384151774\n",
      "F1 score at threshold 0.32 is 0.3909030982201714\n",
      "F1 score at threshold 0.33 is 0.3886337543053961\n",
      "F1 score at threshold 0.34 is 0.38605096303385567\n",
      "F1 score at threshold 0.35 is 0.384399375975039\n",
      "F1 score at threshold 0.36 is 0.37937794040773654\n",
      "F1 score at threshold 0.37 is 0.37547476939772106\n",
      "F1 score at threshold 0.38 is 0.37141249296567247\n",
      "F1 score at threshold 0.39 is 0.3666156871313087\n",
      "F1 score at threshold 0.4 is 0.36172765446910615\n",
      "F1 score at threshold 0.41 is 0.3543246170509051\n",
      "F1 score at threshold 0.42 is 0.34490445859872615\n",
      "F1 score at threshold 0.43 is 0.3365706357626704\n",
      "F1 score at threshold 0.44 is 0.32708403080013393\n",
      "F1 score at threshold 0.45 is 0.3172070681077372\n",
      "F1 score at threshold 0.46 is 0.3034165338998053\n",
      "F1 score at threshold 0.47 is 0.29299132947976875\n",
      "F1 score at threshold 0.48 is 0.27923275544079673\n",
      "F1 score at threshold 0.49 is 0.2696396650672688\n",
      "F1 score at threshold 0.5 is 0.2541574545804095\n",
      "Best threshold:  0.32\n"
     ]
    }
   ],
   "source": [
    "thresholds = []\n",
    "\n",
    "prediction_noembeddings_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    res = metrics.f1_score(val_y, (prediction_noembeddings_val_y > thresh).astype(int))\n",
    "    thresholds.append([thresh, res])\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, res))\n",
    "    \n",
    "thresholds.sort(key=lambda layer: layer[1], reverse=True)\n",
    "best_thresh = thresholds[0][0]\n",
    "print(\"Best threshold: \", best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375806/375806 [==============================] - 18s 48us/step\n"
     ]
    }
   ],
   "source": [
    "'''Set predictions as well and save them'''\n",
    "prediction_noembeddings_test_y = model.predict([test_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, model_input, layer\n",
    "gc.collect()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glove\n",
    "Use embeddings and rebuild the model again to see the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sneakysneak/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3214: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if (yield from self.run_code(code, result)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 10, 300)           150000    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 10, 128)           140160    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 292,241\n",
      "Trainable params: 292,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# embedding_file = '/Users/sneakysneak/Downloads/quora_dataset/glove.840B.300d/glove.840B.300d.txt'\n",
    "embedding_file = 'glove.840B.300d.txt'\n",
    "\n",
    "def get_coefficient(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefficient(*o.split(\" \")) for o in \n",
    "                        open(embedding_file))\n",
    "\n",
    "all_embeddings = np.stack(embeddings_index.values())\n",
    "mean_embeddings, std_embeddings = all_embeddings.mean(), all_embeddings.std()\n",
    "embedding_size = all_embeddings.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "\n",
    "# EMBEDDING MATRIX\n",
    "embedding_matrix = np.random.normal(mean_embeddings, std_embeddings, (nb_words, embedding_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "model_input = Input(shape=(max_length_question,))\n",
    "layer = Embedding(max_features, embedding_size)(model_input)\n",
    "layer = Bidirectional(GRU(64, return_sequences=True))(layer)\n",
    "layer = GlobalMaxPool1D()(layer)\n",
    "layer = Dense(16, activation=\"relu\")(layer)\n",
    "layer = Dropout(0.1)(layer)\n",
    "layer = Dense(1, activation=\"sigmoid\")(layer)\n",
    "model = Model(inputs=model_input, outputs=layer)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/1\n",
      " 546304/1175509 [============>.................] - ETA: 3:18 - loss: 0.1723 - acc: 0.9420"
     ]
    }
   ],
   "source": [
    "## Train the model \n",
    "model.fit(train_X, train_y, batch_size=512, epochs=1, validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = []\n",
    "\n",
    "prediction_glove_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    res = metrics.f1_score(val_y, (prediction_glove_val_y > thresh).astype(int))\n",
    "    thresholds.append([thresh, res])\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, res))\n",
    "    \n",
    "thresholds.sort(key=lambda layer: layer[1], reverse=True)\n",
    "best_thresh = thresholds[0][0]\n",
    "print(\"Best threshold: \", best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Set predictions as well and save them'''\n",
    "prediction_glove_test_y = model.predict([test_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del word_index, embeddings_index, all_embeddings, embedding_matrix, model, \n",
    "model_input, layer\n",
    "gc.collect()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FastText Embeddings:\n",
    "FastText trained on WikiNews corpus and rebuild the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sneakysneak/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3214: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if (yield from self.run_code(code, result)):\n",
      "INFO:plaidml:Opening device \"metal_amd_radeon_pro_560.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 10, 300)           150000    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 10, 128)           140160    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 292,241\n",
      "Trainable params: 292,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# embedding_file = '/Users/sneakysneak/Downloads/quora_dataset/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "embedding_file = 'wiki-news-300d-1M.vec'\n",
    "\n",
    "def get_coefficient(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefficient(*o.split(\" \")) for o in open(embedding_file) if len(o)>100)\n",
    "\n",
    "all_embeddings = np.stack(embeddings_index.values())\n",
    "mean_embeddings,std_embeddings = all_embeddings.mean(), all_embeddings.std()\n",
    "embedding_size = all_embeddings.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(mean_embeddings, std_embeddings, (nb_words, embedding_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "model_input = Input(shape=(max_length_question,))\n",
    "layer = Embedding(max_features, embedding_size)(model_input)\n",
    "layer = Bidirectional(GRU(64, return_sequences=True))(layer)\n",
    "layer = GlobalMaxPool1D()(layer)\n",
    "layer = Dense(16, activation=\"relu\")(layer)\n",
    "layer = Dropout(0.1)(layer)\n",
    "layer = Dense(1, activation=\"sigmoid\")(layer)\n",
    "model = Model(inputs=model_input, outputs=layer)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/1\n",
      "1175509/1175509 [==============================] - 456s 388us/step - loss: 0.1671 - acc: 0.9422 - val_loss: 0.1576 - val_acc: 0.9426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1f936d30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, batch_size=512, epochs=1, validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130613/130613 [==============================] - 28s 215us/step\n",
      "F1 score at threshold 0.1 is 0.4182891504418289\n",
      "F1 score at threshold 0.11 is 0.4263967235916854\n",
      "F1 score at threshold 0.12 is 0.43572329090243606\n",
      "F1 score at threshold 0.13 is 0.4429638431505687\n",
      "F1 score at threshold 0.14 is 0.4480522345259628\n",
      "F1 score at threshold 0.15 is 0.4526850707320423\n",
      "F1 score at threshold 0.16 is 0.45549067084460904\n",
      "F1 score at threshold 0.17 is 0.4569666111818271\n",
      "F1 score at threshold 0.18 is 0.4600848827809216\n",
      "F1 score at threshold 0.19 is 0.46061990550854054\n",
      "F1 score at threshold 0.2 is 0.4607858947481589\n",
      "F1 score at threshold 0.21 is 0.4611310344827586\n",
      "F1 score at threshold 0.22 is 0.46190449215430807\n",
      "F1 score at threshold 0.23 is 0.45986078886310905\n",
      "F1 score at threshold 0.24 is 0.45974412377268664\n",
      "F1 score at threshold 0.25 is 0.4594693281402142\n",
      "F1 score at threshold 0.26 is 0.4573667516636607\n",
      "F1 score at threshold 0.27 is 0.4548456750920869\n",
      "F1 score at threshold 0.28 is 0.45226652812053514\n",
      "F1 score at threshold 0.29 is 0.449485903814262\n",
      "F1 score at threshold 0.3 is 0.4462048886180513\n",
      "F1 score at threshold 0.31 is 0.4422346523030178\n",
      "F1 score at threshold 0.32 is 0.4381421534130893\n",
      "F1 score at threshold 0.33 is 0.4305895920426697\n",
      "F1 score at threshold 0.34 is 0.423818636832033\n",
      "F1 score at threshold 0.35 is 0.4163602251407129\n",
      "F1 score at threshold 0.36 is 0.40903176425564486\n",
      "F1 score at threshold 0.37 is 0.40264900662251657\n",
      "F1 score at threshold 0.38 is 0.3928628325633264\n",
      "F1 score at threshold 0.39 is 0.38759438174880245\n",
      "F1 score at threshold 0.4 is 0.3791390728476821\n",
      "F1 score at threshold 0.41 is 0.3682072117826307\n",
      "F1 score at threshold 0.42 is 0.35735865343116097\n",
      "F1 score at threshold 0.43 is 0.34678624813153963\n",
      "F1 score at threshold 0.44 is 0.33330341918693346\n",
      "F1 score at threshold 0.45 is 0.321285140562249\n",
      "F1 score at threshold 0.46 is 0.3092630406534249\n",
      "F1 score at threshold 0.47 is 0.29626132930513593\n",
      "F1 score at threshold 0.48 is 0.2823913879277201\n",
      "F1 score at threshold 0.49 is 0.2699697649468448\n",
      "F1 score at threshold 0.5 is 0.25926291868392454\n",
      "Best threshold:  0.22\n"
     ]
    }
   ],
   "source": [
    "thresholds = []\n",
    "\n",
    "prediction_fasttext_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    res = metrics.f1_score(val_y, (prediction_fasttext_val_y > thresh).astype(int))\n",
    "    thresholds.append([thresh, res])\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, res))\n",
    "    \n",
    "thresholds.sort(key=lambda layer: layer[1], reverse=True)\n",
    "best_thresh = thresholds[0][0]\n",
    "print(\"Best threshold: \", best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375806/375806 [==============================] - 78s 208us/step\n"
     ]
    }
   ],
   "source": [
    "'''Set predictions as well and save them'''\n",
    "prediction_fasttext_test_y = model.predict([test_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-84b169c798a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_index' is not defined"
     ]
    }
   ],
   "source": [
    "del word_index, embeddings_index, all_embeddings, embedding_matrix, model, \n",
    "model_input, layer\n",
    "gc.collect()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paragram Embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 10, 300)           150000    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 10, 128)           140160    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 292,241\n",
      "Trainable params: 292,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# embedding_file = '/Users/sneakysneak/Downloads/quora_dataset/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "embedding_file = 'paragram_300_sl999.txt'\n",
    "\n",
    "\n",
    "def get_coefficient(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefficient(*o.split(\" \")) for o in open(embedding_file, encoding=\"utf8\", errors='ignore') if len(o)>100)\n",
    "\n",
    "all_embeddings = np.stack(embeddings_index.values())\n",
    "mean_embeddings,std_embeddings = all_embeddings.mean(), all_embeddings.std()\n",
    "embedding_size = all_embeddings.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(mean_embeddings, std_embeddings, (nb_words, embedding_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "        \n",
    "model_input = Input(shape=(max_length_question,))\n",
    "layer = Embedding(max_features, embedding_size)(model_input)\n",
    "layer = Bidirectional(GRU(64, return_sequences=True))(layer)\n",
    "layer = GlobalMaxPool1D()(layer)\n",
    "layer = Dense(16, activation=\"relu\")(layer)\n",
    "layer = Dropout(0.1)(layer)\n",
    "layer = Dense(1, activation=\"sigmoid\")(layer)\n",
    "model = Model(inputs=model_input, outputs=layer)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/1\n",
      "1175040/1175509 [============================>.] - ETA: 0s - loss: 0.1668 - acc: 0.9423"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:plaidml:Caused GPU Timeout Error (IOAF code 2)\n",
      "ERROR:plaidml:Caused GPU Timeout Error (IOAF code 2)\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_X, train_y, batch_size=512, epochs=1, validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = []\n",
    "\n",
    "prediction_paragram_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    res = metrics.f1_score(val_y, (prediction_paragram_val_y > thresh).astype(int))\n",
    "    thresholds.append([thresh, res])\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, res))\n",
    "    \n",
    "thresholds.sort(key=lambda layer: layer[1], reverse=True)\n",
    "best_thresh = thresholds[0][0]\n",
    "print(\"Best threshold: \", best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_paragram_test_y = model.predict([test_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del word_index, embeddings_index, all_embeddings, embedding_matrix, model, \n",
    "model_input, layer\n",
    "gc.collect()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- Overall pretrained embeddings seem to give better results comapred to non-pretrained model.\n",
    "- The performance of the different pretrained embeddings are almost similar.\n",
    "\n",
    "#### Final thoughts:\n",
    "Despite the results of the models with different pre-trained embeddings are similiar, there is a good chance that they might capture different type of information from the data. So let us do a mixture of these three models by averaging their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_y = 0.33*prediction_glove_val_y + 0.33*prediction_fasttext_val_y + 0.34*prediction_paragram_val_y \n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_val_y>thresh).astype(int))))\n",
    "thresholds.sort(key=lambda layer: layer[1], reverse=True)\n",
    "best_thresh = thresholds[0][0]\n",
    "print(\"Best threshold: \", best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_y = 0.33*prediction_glove_test_y + 0.33*prediction_fasttext_test_y + 0.34*prediction_paragram_test_y\n",
    "pred_test_y = (pred_test_y>0.35).astype(int)\n",
    "out_df = pd.DataFrame({\"qid\":test_data_frame[\"qid\"].values})\n",
    "out_df['prediction'] = pred_test_y\n",
    "out_df.to_csv(\"submission_embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
