{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description\n",
    "In this evaluation a Sequentail Bidirectional GRU model is being evaluated, compared to its non-Sequential pair (all_embeddings_with_non_sequential_BiGRU_model.pynb). Glove and FastText Embeddings were used.\n",
    "\n",
    "All read file variables (like train.csv, embeddings files etc) are set to relative path, which means just drag the competition files in to the program's folder and it reads in them automatically. \n",
    "Furthermore, I turned off the support for AMD Radeon GPUs, turn it on if necessary (for quicker computing on Radeon machines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sneakysneak/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/sneakysneak/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/sneakysneak/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/sneakysneak/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/sneakysneak/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/sneakysneak/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# support for AMD Radeon GPU - if you run this on AMD Radeon GPU computer, then use it\n",
    "\n",
    "# import plaidml.keras\n",
    "# plaidml.keras.install_backend()\n",
    "# import os\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "\n",
    "# keras layers, tokenizer, model, sequential etc.\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, SimpleRNN, RNN, LSTM, GRU, Embedding, Dropout, Activation, Flatten, Conv1D, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "import tensorflow as tf\n",
    "# time for idle the system after deleting models and embedding to test in one notebook\n",
    "import time\n",
    "# linear algebra\n",
    "import numpy as np \n",
    "# data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pandas as pd \n",
    "# monitor loading time where it is supported\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import gc\n",
    "\n",
    "random_seed = 63445\n",
    "lsize = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1306122, 3)\n",
      "Test shape :  (375806, 2)\n"
     ]
    }
   ],
   "source": [
    "# train_df = pd.read_csv(\"/Users/sneakysneak/Downloads/quora_dataset/train.csv\")\n",
    "# test_df = pd.read_csv(\"/Users/sneakysneak/Downloads/quora_dataset/test.csv\")]\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "print(\"Train shape : \",train_df.shape)\n",
    "print(\"Test shape : \",test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split the data frame to train and val\n",
    "train_data_frame, value_data_frame = train_test_split(train_data_frame, test_size=0.1, random_state=2018)\n",
    "\n",
    "## configuration values \n",
    "# 300 \n",
    "embedding_size = 300 # the size of each word vector\n",
    "# 50000\n",
    "max_features = 50000 # the size of unique words in use - the number of rows in the embedding vector\n",
    "# 100 \n",
    "max_length_question = 100 # the size of the number of words in each question\n",
    "\n",
    "## first fill all missing values up\n",
    "train_X = train_data_frame[\"question_text\"].fillna(\"_na_\").values\n",
    "val_X = value_data_frame[\"question_text\"].fillna(\"_na_\").values\n",
    "test_X = test_data_frame[\"question_text\"].fillna(\"_na_\").values\n",
    "\n",
    "## tokenize with Keras\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_X))\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "val_X = tokenizer.texts_to_sequences(val_X)\n",
    "test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "## sentence padding\n",
    "train_X = pad_sequences(train_X, maxlen=max_length_question)\n",
    "val_X = pad_sequences(val_X, maxlen=max_length_question)\n",
    "test_X = pad_sequences(test_X, maxlen=max_length_question)\n",
    "\n",
    "## save the target values as train_y and val_y\n",
    "train_y = train_data_frame['target'].values\n",
    "val_y = value_data_frame['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glove embeddings\n",
    "#####  In the for loop with the  help of the  tqdm library (a command line “display interface” which displays time and bar when something is loading). Values splits by space. Word set to 0 values, counting from 0. Coefs is a numpy array conversion of values variable with the float32 data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196017it [04:29, 8159.25it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2196016 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings glove text file\n",
    "embeddings_index = {}\n",
    "# glove_emb = open('/Users/sneakysneak/Downloads/quora_dataset/glove.840B.300d/glove.840B.300d.txt')\n",
    "glove_emb = open('glove.840B.300d.txt')\n",
    "\n",
    "\n",
    "for line in tqdm(glove_emb):\n",
    "    values = line.split(\" \")\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "glove_emb.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this function creating a numpy array filled with 300 zeros. Text variable’s length split to 30. Embeds variable iterates through on the empty_emb 300 zeros and adds them in 30 minus the number of embeds. So, it’s “filling” them up and returns the numpy array with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert values to embeddings\n",
    "def text_to_array(text):\n",
    "    empyt_emb = np.zeros(300)\n",
    "    text = text[:-1].split()[:30]\n",
    "    embeds = [embeddings_index.get(x, empyt_emb) for x in text]\n",
    "    embeds+= [empyt_emb] * (30 - len(embeds))\n",
    "    return np.array(embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this new variable val_vects populates this new array with the np.array about text_to_array method from above, with the train_df dummy variable which is the train.csv. Applying tqdm loading screen and the “qhestom text” tab ln the csv file and iterates through on 3000 at once. Val_y creates an array from the “target” tab of the csv, 3000 at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 3586.68it/s]\n"
     ]
    }
   ],
   "source": [
    "val_vects = np.array([text_to_array(train_data_frame) for train_data_frame in tqdm(value_data_frame[\"question_text\"][:3000])])\n",
    "val_y = np.array(value_data_frame[\"target\"][:3000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define batch_size variable. Define batch_gen fucntion with the train_df variable, which is the train.csv file. This function creates batches from the train.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "def batch_gen(train_data_frame):\n",
    "    n_batches = math.ceil(len(train_data_frame) / batch_size)\n",
    "    while True: \n",
    "        train_data_frame = train_data_frame.sample(frac=1.)  # Shuffle the data.\n",
    "        for i in range(n_batches):\n",
    "            texts = train_data_frame.iloc[i*batch_size:(i+1)*batch_size, 1]\n",
    "            text_arr = np.array([text_to_array(text) for text in texts])\n",
    "            yield text_arr, np.array(train_data_frame[\"target\"][i*batch_size:(i+1)*batch_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bidirectional GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"metal_amd_radeon_pro_560.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 30, 128)           140160    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               74112     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 1032      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 215,313\n",
      "Trainable params: 215,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(GRU(64, return_sequences=True, recurrent_dropout=0.5),\n",
    "                      input_shape=(30,300))) \n",
    "model.add(Bidirectional(GRU(64)))\n",
    "model.add(Dense(8))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The mg is the variable instantiated from the batch_gen function above, the dummy variable in it is the train_df, which is the train.csv dataset. \n",
    "##### The .fit_generator inbuilt keras function, which trains the model on the dataset batch-by-batch. The mg comes first, after the number of epochs, and the step_per_epoch, which is the total number of steps in batches of samples before declaring one epoch is finished and between the next epoch starting.\n",
    "##### The validation_data is an immutable sequence , a tuple, val_vects, val_y, so the vector texts and the target values, 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 3263 of 9555 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 7601 of 9555 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1352 - acc: 0.9483"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 3161 of 3904 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 0.1353 - acc: 0.9482 - val_loss: 0.3630 - val_acc: 0.9363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a44008f28>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mg = batch_gen(train_data_frame)\n",
    "model.fit_generator(mg, epochs=1,\n",
    "                    steps_per_epoch=1000,\n",
    "                    validation_data=(val_vects, val_y),\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a dictionary variable as thresholds. Using the inbuilt keras .predict function with val_vects, defined batch size and verbose is 1. The for loop iterates through a numpy array trying to determine the best f1_score and its threshold value. In the last 3 lines, prints out the best threshold value, which is 0.33 in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 2469 of 3870 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/3000 [===================>..........] - ETA: 2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 3355 of 3870 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 9s 3ms/step\n",
      "F1 score at threshold 0.1 is 0.5119047619047619\n",
      "F1 score at threshold 0.11 is 0.5198776758409785\n",
      "F1 score at threshold 0.12 is 0.524031007751938\n",
      "F1 score at threshold 0.13 is 0.5399361022364217\n",
      "F1 score at threshold 0.14 is 0.5463414634146341\n",
      "F1 score at threshold 0.15 is 0.5535420098846787\n",
      "F1 score at threshold 0.16 is 0.5536912751677852\n",
      "F1 score at threshold 0.17 is 0.5559322033898305\n",
      "F1 score at threshold 0.18 is 0.5626072041166381\n",
      "F1 score at threshold 0.19 is 0.5709281961471103\n",
      "F1 score at threshold 0.2 is 0.5759717314487632\n",
      "F1 score at threshold 0.21 is 0.5785714285714286\n",
      "F1 score at threshold 0.22 is 0.5858951175406872\n",
      "F1 score at threshold 0.23 is 0.5919117647058824\n",
      "F1 score at threshold 0.24 is 0.5955056179775281\n",
      "F1 score at threshold 0.25 is 0.6011342155009453\n",
      "F1 score at threshold 0.26 is 0.6068702290076337\n",
      "F1 score at threshold 0.27 is 0.6150870406189555\n",
      "F1 score at threshold 0.28 is 0.6186770428015563\n",
      "F1 score at threshold 0.29 is 0.615686274509804\n",
      "F1 score at threshold 0.3 is 0.6212424849699398\n",
      "F1 score at threshold 0.31 is 0.6272912423625254\n",
      "F1 score at threshold 0.32 is 0.629399585921325\n",
      "F1 score at threshold 0.33 is 0.634453781512605\n",
      "F1 score at threshold 0.34 is 0.6353944562899786\n",
      "F1 score at threshold 0.35 is 0.6363636363636365\n",
      "F1 score at threshold 0.36 is 0.631578947368421\n",
      "F1 score at threshold 0.37 is 0.6367713004484306\n",
      "F1 score at threshold 0.38 is 0.6425339366515836\n",
      "F1 score at threshold 0.39 is 0.6378132118451025\n",
      "F1 score at threshold 0.4 is 0.6433566433566433\n",
      "F1 score at threshold 0.41 is 0.6416861826697892\n",
      "F1 score at threshold 0.42 is 0.6462264150943396\n",
      "F1 score at threshold 0.43 is 0.6476190476190476\n",
      "F1 score at threshold 0.44 is 0.645933014354067\n",
      "F1 score at threshold 0.45 is 0.6521739130434783\n",
      "F1 score at threshold 0.46 is 0.6405867970660147\n",
      "F1 score at threshold 0.47 is 0.6336633663366337\n",
      "F1 score at threshold 0.48 is 0.6384039900249376\n",
      "F1 score at threshold 0.49 is 0.6381909547738693\n",
      "F1 score at threshold 0.5 is 0.6310432569974554\n",
      "Best threshold:  0.45\n"
     ]
    }
   ],
   "source": [
    "thresholds = []\n",
    "\n",
    "pred_glove_val_y = model.predict([val_vects], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    res = metrics.f1_score(val_y, (pred_glove_val_y > thresh).astype(int))\n",
    "    thresholds.append([thresh, res])\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, res))\n",
    "    \n",
    "thresholds.sort(key=lambda x: x[1], reverse=True)\n",
    "best_thresh = thresholds[0][0]\n",
    "print(\"Best threshold: \", best_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In here, the model is deleted and gc is the garbage collector collects the leftover of the remaining model, and the program idle for 10 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, embeddings_index#, embedding_matrix, inp, all_embs\n",
    "gc.collect()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999995it [01:53, 8828.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 999995 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings glove text file\n",
    "embeddings_index = {}\n",
    "# fasttext_emb = open('/Users/sneakysneak/Downloads/quora_dataset/wiki-news-300d-1M/wiki-news-300d-1M.vec')\n",
    "fasttext_emb = open('wiki-news-300d-1M.vec')\n",
    "\n",
    "\n",
    "for line in tqdm(fasttext_emb):\n",
    "    values = line.split(\" \")\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "fasttext_emb.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert values to embeddings\n",
    "def text_to_array(text):\n",
    "    empyt_emb = np.zeros(300)\n",
    "    text = text[:-1].split()[:30]\n",
    "    embeds = [embeddings_index.get(x, empyt_emb) for x in text]\n",
    "    embeds+= [empyt_emb] * (30 - len(embeds))\n",
    "    return np.array(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 9162.23it/s]\n"
     ]
    }
   ],
   "source": [
    "val_vects = np.array([text_to_array(train_data_frame) for train_data_frame in tqdm(value_data_frame[\"question_text\"][:3000])])\n",
    "val_y = np.array(value_data_frame[\"target\"][:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "def batch_gen(train_data_frame):\n",
    "    n_batches = math.ceil(len(train_data_frame) / batch_size)\n",
    "    while True: \n",
    "        train_data_frame = train_data_frame.sample(frac=1.)  # Shuffle the data.\n",
    "        for i in range(n_batches):\n",
    "            texts = train_data_frame.iloc[i*batch_size:(i+1)*batch_size, 1]\n",
    "            text_arr = np.array([text_to_array(text) for text in texts])\n",
    "            yield text_arr, np.array(train_data_frame[\"target\"][i*batch_size:(i+1)*batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_3 (Bidirection (None, 30, 128)           140160    \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 128)               74112     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 1032      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 215,313\n",
      "Trainable params: 215,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(GRU(64, return_sequences=True, recurrent_dropout=0.5),\n",
    "                      input_shape=(30,300))) \n",
    "model.add(Bidirectional(GRU(64)))\n",
    "model.add(Dense(8))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 159s 159ms/step - loss: 0.1391 - acc: 0.9481 - val_loss: 0.3844 - val_acc: 0.9360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ab0135128>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mg = batch_gen(train_data_frame)\n",
    "model.fit_generator(mg, epochs=1,\n",
    "                    steps_per_epoch=1000,\n",
    "                    validation_data=(val_vects, val_y),\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 1s 280us/step\n",
      "F1 score at threshold 0.1 is 0.6156787762906311\n",
      "F1 score at threshold 0.11 is 0.6186770428015563\n",
      "F1 score at threshold 0.12 is 0.6239999999999999\n",
      "F1 score at threshold 0.13 is 0.6262626262626263\n",
      "F1 score at threshold 0.14 is 0.6335403726708075\n",
      "F1 score at threshold 0.15 is 0.6276150627615062\n",
      "F1 score at threshold 0.16 is 0.6367521367521368\n",
      "F1 score at threshold 0.17 is 0.6336206896551724\n",
      "F1 score at threshold 0.18 is 0.6373626373626374\n",
      "F1 score at threshold 0.19 is 0.6410835214446954\n",
      "F1 score at threshold 0.2 is 0.6376146788990826\n",
      "F1 score at threshold 0.21 is 0.6448598130841121\n",
      "F1 score at threshold 0.22 is 0.6365795724465558\n",
      "F1 score at threshold 0.23 is 0.6426858513189448\n",
      "F1 score at threshold 0.24 is 0.6390243902439023\n",
      "F1 score at threshold 0.25 is 0.6403940886699507\n",
      "F1 score at threshold 0.26 is 0.63681592039801\n",
      "F1 score at threshold 0.27 is 0.6397984886649875\n",
      "F1 score at threshold 0.28 is 0.6288659793814433\n",
      "F1 score at threshold 0.29 is 0.6337662337662339\n",
      "F1 score at threshold 0.3 is 0.6299212598425197\n",
      "F1 score at threshold 0.31 is 0.6296296296296297\n",
      "F1 score at threshold 0.32 is 0.624\n",
      "F1 score at threshold 0.33 is 0.6219839142091153\n",
      "F1 score at threshold 0.34 is 0.6103542234332425\n",
      "F1 score at threshold 0.35 is 0.6022099447513812\n",
      "F1 score at threshold 0.36 is 0.5882352941176472\n",
      "F1 score at threshold 0.37 is 0.586894586894587\n",
      "F1 score at threshold 0.38 is 0.5936599423631124\n",
      "F1 score at threshold 0.39 is 0.5637982195845698\n",
      "F1 score at threshold 0.4 is 0.5568862275449102\n",
      "F1 score at threshold 0.41 is 0.5481927710843373\n",
      "F1 score at threshold 0.42 is 0.5454545454545454\n",
      "F1 score at threshold 0.43 is 0.5292307692307693\n",
      "F1 score at threshold 0.44 is 0.53125\n",
      "F1 score at threshold 0.45 is 0.5345911949685535\n",
      "F1 score at threshold 0.46 is 0.5239616613418531\n",
      "F1 score at threshold 0.47 is 0.5064935064935064\n",
      "F1 score at threshold 0.48 is 0.5033112582781457\n",
      "F1 score at threshold 0.49 is 0.5033557046979866\n",
      "F1 score at threshold 0.5 is 0.5033557046979866\n",
      "Best threshold:  0.21\n"
     ]
    }
   ],
   "source": [
    "thresholds = []\n",
    "\n",
    "pred_fasttext_val_y = model.predict([val_vects], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    res = metrics.f1_score(val_y, (pred_fasttext_val_y > thresh).astype(int))\n",
    "    thresholds.append([thresh, res])\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, res))\n",
    "    \n",
    "thresholds.sort(key=lambda x: x[1], reverse=True)\n",
    "best_thresh = thresholds[0][0]\n",
    "print(\"Best threshold: \", best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, embeddings_index#, embedding_matrix, inp, all_embs\n",
    "gc.collect()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
